[
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#target-audience-unclear",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#target-audience-unclear",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Target Audience Unclear",
    "text": "Target Audience Unclear\n\nIf you are a footy fan this article will likely present as some mildy interesting footy facts, combined with incomprehensible techno-babble. For R users this will likely appear to be a fairly elementary data wrangling exercise, combined with a bunch of references you don’t understand. But if you are both a footy fan and an R user, it will hopefully prove to be a quite interesting read."
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#the-fitzroy-package",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#the-fitzroy-package",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "The fitzRoy Package",
    "text": "The fitzRoy Package\nThe first step in analysing AFL data is obtaining the data (“collection”). Our first thought might be to search the web for publicly available AFL datasets and APIs or even scrape the data from websites such as the official AFL website, Footywire or AFL Tables. But there is a more straight-forward way.\nWhile most people now know Fitzroy as a trendy inner city suburb of Melbourne, filled with terraces and over-priced croissants, it was once home9 to the mighty (and now merged out of existence) Fitzroy Lions Football Club.9 It is also (regrettably) the place of my birth but as a WA boy I don’t like to talk about the fact that my parents happened to be in Melbourne when I was born.\n\n\n\n\nWe can obtain the data we need very simply using its name-sake, the fitzRoy R package. It abstracts away all the web scraping and API calls for us into a very helpful family of fetch_* functions.\nSo let’s begin by loading the fitzRoy package and while we’re at it, I will also load all the other packages I will be using.\n\nlibrary(fitzRoy)\n\n# Note that I generally avoid mixing dplyr and data.table at the same time\n#   but the reason I have done with will become apparent later\nlibrary(dplyr)\nlibrary(data.table)\n\nlibrary(rvest)\nlibrary(stringr)\n\n\nfitzRoy Data Sources\nfitzRoy provides access to a number of footy data sources10 including AFL Tables and the official AFL website. Each data source has its own advantages and disadvantages, for example:10 Up-to-date information on data sources can be found on fitzRoy’s documentation site\n\nAFL Tables has the entirety of AFL/VFL history (1897 to present) but lacks some of the more advanced stats.\nThe official AFL website only has data from 2014 onwards but it also probably the most complete in terms of the advanced statistics it contains (e.g. centre bounce attendances11).\n\n11 Centre bounce attendances (CBAs) are a commonly-used metrics in AFL fantasy, coaches often look at tools such as this one to help with researching their trades.Where possible we will use the AFL Tables data set as it has the full history of the AFL on it. However if we require stats that it is missing, we will simply have to adopt a different data source and caveat it by saying it is only for a subset of the full history of the competition.\nThe fetch_* family of functions from the fitzRoy package allow us to read the package. Consult the documentation site for a complete list of all the available functions. Below we will get the data we need to answer our questions:\n\nplayer_stats &lt;- fitzRoy::fetch_player_stats(season = 1897:2023)\nresults &lt;- fitzRoy::fetch_results(season = 1897:2023)\n\n\n\n\n\n\n\nBeing a good citizen\n\n\n\nWhen sourcing data from fitzRoy, it is important to follow good data collection12 etiquette by only downloading the data you need and avoiding repeatedly downloading the same data over and over again. This prevents servers being overloaded and will mean everyone will get their data faster.\nIn keeping with this, for the purposes of this blog post, I have saved the data in a local RDS file instead of repeatedly calling the fetch_* functions, I use readRDS(). The code for this is below (and the code above is not actually run but is cleaner for demonstration purposes):\n\nif(file.exists(\"data/player_stats.RDS\")) {\n  player_stats &lt;- readRDS(\"data/player_stats.RDS\")\n  \n} else {\n  player_stats &lt;- fitzRoy::fetch_player_stats_afltables(season = 1897:2023)\n  saveRDS(player_stats, \"data/player_stats.RDS\")\n}\n\nif(file.exists(\"data/results.RDS\")) {\n  results &lt;- readRDS(\"data/results.RDS\")\n  \n} else {\n  results &lt;- fitzRoy::fetch_results_afltables(season = 1897:2023)\n  saveRDS(results, \"data/results.RDS\")\n}\n\n\n\n12 this topic is discussed on the fitzRoy documentation site hereThe data we have read in is as at round R tail(player_stats$Round, 1) of the R tail(player_stats$Season, 1) AFL season."
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#finicky-details-about-other-r-packages",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#finicky-details-about-other-r-packages",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Finicky Details About Other R Packages",
    "text": "Finicky Details About Other R Packages\nTidyverse Versus data.table\n\nIn the R community, there is an ongoing power struggle between using the Posit13-backed tidyverse and the heavily-optimised data.table.13 formally known as RStudio (RIP)\nAs to not unsettle people who prefer either dplyr (and the tidyverse) or data.table, I have written code in both packages as to not alienate anyone14. Where relevant, I have used a tabbed layout for the convenience of the reader. As my personal preference for readability purposes is the tidyverse15, I will place this code in the first tab.14 note that I have not written a base R dataframes version because I can see arguments for using both tidyverse and data.table but base R data.frames will probably cause more pain than they are worth (there is a reason that tidyverse and data.table exist)15 I will typically will only use data.table if the size of data necessitates it. In this case, the data is less than a million rows so there are no problems.\n\n\nTidyverse\ndata.table\n\n\n\nNote that the code below is somewhat redundant as the fitzRoy package follows the tidyverse philosophy and returns tibbles. However this is add the _tb suffix16 to distinguish it from the data.table code.16 an abbreviation of “tibble”\n\nplayer_stats_tb &lt;- as_tibble(player_stats)\nresults_tb &lt;- as_tibble(results)\n\n\n\nHenceforth, all data.table code will use the _dt suffix17 as to distinguish it from the tidyverse code.17 an acronym of “data.table”\n\nplayer_stats_dt &lt;- as.data.table(player_stats)\nresults_dt &lt;- as.data.table(results)\n\n\n\n\nAdoption of the Native Pipe Operator (|&gt;)\nThe so-called pipe operator (%&gt;%) of the magrittr package has been a core staple of tidyverse since its inception but since the R core team introduced the so-called native pipe (|&gt;) to base R (in version 4.118), this has led to a split in adoption. There are some nuances in its usage19 but it overall behaves in a similar way to the magrittr pipe and has less overhead (and is therefore faster). While the native pipe was initially missing some of the key features of the magrittr pipe, new features20 have been added to it that (in my mind) mean that it might have even surpassed the magrittr pipe.18 another cool thing introduced in this version of R was so-called function shorthand (\\()), see help(\"function\") for more details19 I may even cover these in a future blog post20 In R version 4.2, the _ symbol was added as a placeholder character and in R version 4.3, extractions using the $ symbol are now allowed\nWhile I have tried to appease people in both the tidyverse and data.table camps, I will not be re-writing my code more than once with such as minor syntactic difference as the pipe I use. I will therefore be dragging all my tidyverse-using readers kicking and screaming into the R 4.1 world by adopting the native pipe (|&gt;) in my tidyverse code.\n\nNote that the common RStudio shortcut, Ctrl+Shift+M can be changed from the magrittr pipe (%&gt;%), which is still the default, to the native pipe (|&gt;).\n\nWebscraping package\nWhile the majority of our data will be sourced using the fitzRoy package, a small amount of data (namely Norm Smith medalists, which are outside of the scope of fitzRoy) will require us to perform some bespoke web scraping. This will be performed using the rvest package (loaded above)."
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#preliminary-data-work",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#preliminary-data-work",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Preliminary Data Work",
    "text": "Preliminary Data Work\nFlattening the Data\nTo begin with, let’s scrutinise the results data in order to figure out what we have to work with.\n\nstr(results)\n\ntibble [16,352 × 16] (S3: tbl_df/tbl/data.frame)\n $ Game        : num [1:16352] 1 2 3 4 5 6 7 8 9 10 ...\n $ Date        : Date[1:16352], format: \"1897-05-08\" \"1897-05-08\" ...\n $ Round       : chr [1:16352] \"R1\" \"R1\" \"R1\" \"R1\" ...\n $ Home.Team   : chr [1:16352] \"Fitzroy\" \"Collingwood\" \"Geelong\" \"Sydney\" ...\n $ Home.Goals  : int [1:16352] 6 5 3 3 6 4 3 9 6 5 ...\n $ Home.Behinds: int [1:16352] 13 11 6 9 4 6 8 10 5 9 ...\n $ Home.Points : int [1:16352] 49 41 24 27 40 30 26 64 41 39 ...\n $ Away.Team   : chr [1:16352] \"Carlton\" \"St Kilda\" \"Essendon\" \"Melbourne\" ...\n $ Away.Goals  : int [1:16352] 2 2 7 6 5 8 10 3 5 7 ...\n $ Away.Behinds: int [1:16352] 4 4 5 8 6 2 6 1 7 8 ...\n $ Away.Points : int [1:16352] 16 16 47 44 36 50 66 19 37 50 ...\n $ Venue       : chr [1:16352] \"Brunswick St\" \"Victoria Park\" \"Corio Oval\" \"Lake Oval\" ...\n $ Margin      : int [1:16352] 33 25 -23 -17 4 -20 -40 45 4 -11 ...\n $ Season      : num [1:16352] 1897 1897 1897 1897 1897 ...\n $ Round.Type  : chr [1:16352] \"Regular\" \"Regular\" \"Regular\" \"Regular\" ...\n $ Round.Number: int [1:16352] 1 1 1 1 2 2 2 2 3 3 ...\n\n\nWhile inspecting the results we may note that certain key match-level information (e.g. quarter-by-quarter scores) for answering some of our question is missing from it. As it turns out, this data is actually available on the player_stats_afl_tables data (one row per player per match) instead. Thus, we will create a ‘flattened’ version of player_stats_afl_tables with all the match-level fields available to us on both datasets.\nNow, let’s take a look at the player_stats_afl_tables dataset to determine which fields are player-level and which are match-level.\n\n\nCode\nOutput\n\n\n\n\nstr(player_stats)\n\nNote that the output has been placed into another tab as it is rather long.\n\n\n\n\ntibble [663,115 × 59] (S3: tbl_df/tbl/data.frame)\n $ Season                 : num [1:663115] 1897 1897 1897 1897 1897 ...\n $ Round                  : chr [1:663115] \"1\" \"1\" \"1\" \"1\" ...\n $ Date                   : Date[1:663115], format: \"1897-05-08\" \"1897-05-08\" ...\n $ Local.start.time       : int [1:663115] 1500 1500 1500 1500 1500 1500 1500 1500 1500 1500 ...\n $ Venue                  : chr [1:663115] \"Brunswick St\" \"Brunswick St\" \"Brunswick St\" \"Brunswick St\" ...\n $ Attendance             : num [1:663115] 3000 3000 3000 3000 3000 3000 3000 3000 3000 3000 ...\n $ Home.team              : chr [1:663115] \"Fitzroy\" \"Fitzroy\" \"Fitzroy\" \"Fitzroy\" ...\n $ HQ1G                   : int [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ HQ1B                   : int [1:663115] 5 5 5 5 5 5 5 5 5 5 ...\n $ HQ2G                   : int [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ HQ2B                   : int [1:663115] 11 11 11 11 11 11 11 11 11 11 ...\n $ HQ3G                   : int [1:663115] 5 5 5 5 5 5 5 5 5 5 ...\n $ HQ3B                   : int [1:663115] 13 13 13 13 13 13 13 13 13 13 ...\n $ HQ4G                   : int [1:663115] 6 6 6 6 6 6 6 6 6 6 ...\n $ HQ4B                   : int [1:663115] 13 13 13 13 13 13 13 13 13 13 ...\n $ Home.score             : int [1:663115] 49 49 49 49 49 49 49 49 49 49 ...\n $ Away.team              : chr [1:663115] \"Carlton\" \"Carlton\" \"Carlton\" \"Carlton\" ...\n $ AQ1G                   : int [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ AQ1B                   : int [1:663115] 3 3 3 3 3 3 3 3 3 3 ...\n $ AQ2G                   : int [1:663115] 1 1 1 1 1 1 1 1 1 1 ...\n $ AQ2B                   : int [1:663115] 3 3 3 3 3 3 3 3 3 3 ...\n $ AQ3G                   : int [1:663115] 2 2 2 2 2 2 2 2 2 2 ...\n $ AQ3B                   : int [1:663115] 3 3 3 3 3 3 3 3 3 3 ...\n $ AQ4G                   : int [1:663115] 2 2 2 2 2 2 2 2 2 2 ...\n $ AQ4B                   : int [1:663115] 4 4 4 4 4 4 4 4 4 4 ...\n $ Away.score             : int [1:663115] 16 16 16 16 16 16 16 16 16 16 ...\n $ First.name             : chr [1:663115] \"Bill\" \"Jimmy\" \"Bob\" \"Tom\" ...\n $ Surname                : chr [1:663115] \"Ahern\" \"Aitken\" \"Armstrong\" \"Blake\" ...\n $ ID                     : num [1:663115] 4415 4416 4417 4419 4421 ...\n $ Jumper.No.             : chr [1:663115] \"0\" \"0\" \"0\" \"0\" ...\n $ Playing.for            : chr [1:663115] \"Carlton\" \"Carlton\" \"Carlton\" \"Carlton\" ...\n $ Kicks                  : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Marks                  : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Handballs              : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Goals                  : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Behinds                : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Hit.Outs               : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Tackles                : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Rebounds               : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Inside.50s             : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Clearances             : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Clangers               : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Frees.For              : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Frees.Against          : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Brownlow.Votes         : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Contested.Possessions  : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Uncontested.Possessions: num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Contested.Marks        : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Marks.Inside.50        : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ One.Percenters         : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Bounces                : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Goal.Assists           : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Time.on.Ground..       : num [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Substitute             : int [1:663115] 0 0 0 0 0 0 0 0 0 0 ...\n $ Umpire.1               : chr [1:663115] \"Samuel Hood\" \"Samuel Hood\" \"Samuel Hood\" \"Samuel Hood\" ...\n $ Umpire.2               : chr [1:663115] \"\" \"\" \"\" \"\" ...\n $ Umpire.3               : chr [1:663115] \"\" \"\" \"\" \"\" ...\n $ Umpire.4               : chr [1:663115] \"\" \"\" \"\" \"\" ...\n $ group_id               : int [1:663115] 2 2 2 2 2 2 2 2 2 2 ...\n\n\n\n\n\nInspecting the fields and using some knowledge of the game, we can determine that the following fields are player-level:\n\nplayer_level_fields &lt;- c(\n  \"First.name\", \"Surname\", \"ID\", \"Jumper.No.\", \"Playing.for\", \"Kicks\", \"Marks\", \n  \"Handballs\", \"Goals\", \"Behinds\", \"Hit.Outs\", \"Tackles\", \"Rebounds\", \"Inside.50s\", \n  \"Clearances\", \"Clangers\", \"Frees.For\", \"Frees.Against\", \"Brownlow.Votes\", \n  \"Contested.Possessions\", \"Uncontested.Possessions\", \"Contested.Marks\", \n  \"Marks.Inside.50\", \"One.Percenters\", \"Bounces\", \"Goal.Assists\", \"Time.on.Ground..\",\n  \"Substitute\"\n  )\n\nmatch_level_fields &lt;- setdiff(colnames(player_stats), player_level_fields)\n\nWe can now safely group and aggregate by the match_level_fields below:\n\n\nTidyverse\ndata.table\n\n\n\n\nplayer_stats_tb |&gt; \n  mutate(\n    home_player = Playing.for == Home.team,\n    away_player = Playing.for == Away.team\n  ) |&gt; \n  group_by(pick(all_of(match_level_fields))) |&gt; \n  summarise(\n    player_count = n(),\n    home_kicks = sum(Kicks * home_player),\n    away_kicks = sum(Kicks * away_player),\n    home_marks = sum(Marks * home_player),\n    away_marks = sum(Marks * away_player),\n    home_handballs = sum(Handballs * home_player),\n    away_handballs = sum(Handballs * away_player),\n    home_hit_outs = sum(Hit.Outs * home_player),\n    away_hit_outs = sum(Hit.Outs * away_player),\n    home_tackles = sum(Tackles * home_player),\n    away_tackles = sum(Tackles * away_player),\n    home_rebounds = sum(Rebounds * home_player),\n    away_rebounds = sum(Rebounds * away_player),\n    home_inside_50s = sum(Inside.50s * home_player),\n    away_inside_50s = sum(Inside.50s * away_player),\n    home_clearances = sum(Clearances * home_player),\n    away_clearances = sum(Clearances * away_player),\n    home_clangers = sum(Clangers * home_player),\n    away_clangers = sum(Clangers * away_player),\n    home_frees_for = sum(Frees.For * home_player),\n    away_frees_for = sum(Frees.For * away_player),\n    home_frees_against = sum(Frees.Against * home_player),\n    away_frees_against = sum(Frees.Against * away_player),\n    home_contested_possessions = sum(Contested.Possessions * home_player),\n    away_contested_possessions = sum(Contested.Possessions * away_player),\n    home_uncontested_possessions = sum(Uncontested.Possessions * home_player),\n    away_uncontested_possessions = sum(Uncontested.Possessions * away_player),\n    home_contested_marks = sum(Contested.Marks * home_player),\n    away_contested_marks = sum(Contested.Marks * away_player),\n    home_marks_inside_50 = sum(Marks.Inside.50 * home_player),\n    away_marks_inside_50 = sum(Marks.Inside.50 * away_player),\n    home_one_percenters = sum(One.Percenters * home_player),\n    away_one_percenters = sum(One.Percenters * away_player),\n    home_bounces = sum(Bounces * home_player),\n    away_bounces = sum(Bounces * away_player),\n    home_goal_assists = sum(Goal.Assists * home_player),\n    away_goal_assists = sum(Goal.Assists * away_player),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(Date, Local.start.time, Home.team) -&gt; \n  match_stats_flat_tb\n\n# verify correct number of games:\nnrow(match_stats_flat_tb) == nrow(results_tb)\n\n[1] TRUE\n\n\n\n\n\nmatch_stats_flat_dt &lt;- copy(player_stats_dt)\n\nmatch_stats_flat_dt[, home_player := Playing.for == Home.team]\nmatch_stats_flat_dt[, away_player := Playing.for == Away.team]\n\nmatch_stats_flat_dt &lt;- match_stats_flat_dt[, .(\n  player_count = .N,\n  home_kicks = sum(Kicks * home_player),\n  away_kicks = sum(Kicks * away_player),\n  home_marks = sum(Marks * home_player),\n  away_marks = sum(Marks * away_player),\n  home_handballs = sum(Handballs * home_player),\n  away_handballs = sum(Handballs * away_player),\n  home_hit_outs = sum(Hit.Outs * home_player),\n  away_hit_outs = sum(Hit.Outs * away_player),\n  home_tackles = sum(Tackles * home_player),\n  away_tackles = sum(Tackles * away_player),\n  home_rebounds = sum(Rebounds * home_player),\n  away_rebounds = sum(Rebounds * away_player),\n  home_inside_50s = sum(Inside.50s * home_player),\n  away_inside_50s = sum(Inside.50s * away_player),\n  home_clearances = sum(Clearances * home_player),\n  away_clearances = sum(Clearances * away_player),\n  home_clangers = sum(Clangers * home_player),\n  away_clangers = sum(Clangers * away_player),\n  home_frees_for = sum(Frees.For * home_player),\n  away_frees_for = sum(Frees.For * away_player),\n  home_frees_against = sum(Frees.Against * home_player),\n  away_frees_against = sum(Frees.Against * away_player),\n  home_contested_possessions = sum(Contested.Possessions * home_player),\n  away_contested_possessions = sum(Contested.Possessions * away_player),\n  home_uncontested_possessions = sum(Uncontested.Possessions * home_player),\n  away_uncontested_possessions = sum(Uncontested.Possessions * away_player),\n  home_contested_marks = sum(Contested.Marks * home_player),\n  away_contested_marks = sum(Contested.Marks * away_player),\n  home_marks_inside_50 = sum(Marks.Inside.50 * home_player),\n  away_marks_inside_50 = sum(Marks.Inside.50 * away_player),\n  home_one_percenters = sum(One.Percenters * home_player),\n  away_one_percenters = sum(One.Percenters * away_player),\n  home_bounces = sum(Bounces * home_player),\n  away_bounces = sum(Bounces * away_player),\n  home_goal_assists = sum(Goal.Assists * home_player),\n  away_goal_assists = sum(Goal.Assists * away_player)\n), by = match_level_fields]\n\nsetorder(match_stats_flat_dt, Date, Local.start.time, Home.team)\n\n# verify outputs match:\nidentical(as.data.frame(match_stats_flat_tb), as.data.frame(match_stats_flat_dt))\n\n[1] TRUE\n\n\n\n\n\nHenceforth, player_stats_* and match_stats_flat_* will be the two datasets we will use predominantly.\nIDs and URLs\nOne thing that our match_stats_flat_* dataset is currently lacking is a game ID for use as a primary key. In addition, being able to link directly to AFL tables when talking about particular game or players would be handy.\nGame ID and URL\nLet’s tackle the game ID by writing some functions to an ID which also conveniently lines up with the way AFL Tables game URLs work (two birds with one stone).\n\nteam_code_map &lt;- c(\n  \"Adelaide\" = \"01\",\n  \"Brisbane Bears\" = \"02\",\n  \"Carlton\" = \"03\",\n  \"Collingwood\" = \"04\",\n  \"Essendon\" = \"05\",\n  \"Fitzroy\" = \"06\",\n  \"Western Bulldogs\" = \"07\",\n  \"Fremantle\" = \"08\",\n  \"Geelong\" = \"09\",\n  \"Hawthorn\" = \"10\",\n  \"Melbourne\" = \"11\",\n  \"North Melbourne\" = \"12\",\n  \"Port Adelaide\" = \"13\",\n  \"Richmond\" = \"14\",\n  \"St Kilda\" = \"15\",\n  \"Sydney\" = \"16\",\n  \"University\" = \"17\",\n  \"West Coast\" = \"18\",\n  \"Brisbane Lions\" = \"19\",\n  \"Gold Coast\" = \"20\",\n  \"Greater Western Sydney\" = \"21\"\n)\n\n# The three functions below are all vectorised for efficiency purposes\nget_team_code &lt;- function(team_name) {\n team_code_map[team_name]\n}\n\nget_game_id &lt;- function(home_team_code, away_team_code, game_date) {\n  # example ID: 161820230624\n  game_date_string &lt;- format(game_date, \"%Y%m%d\")\n  \n  ifelse(\n    home_team_code &gt; away_team_code, \n    # the smaller code is always first\n    paste0(away_team_code, home_team_code, game_date_string),\n    paste0(home_team_code, away_team_code, game_date_string)\n    )\n}\n\nget_game_afltables_url &lt;- function(game_id, season) {\n  # example url: https://afltables.com/afl/stats/games/2023/161820230624.html\n  paste0(\"https://afltables.com/afl/stats/games/\", season,\"/\", game_id, \".html\")\n}\n\nNow lets use these functions21 to add a primary key to our match_stats_flat_* datasets.21 Note that as the functions are vectorised, we need not use the slow purrr::map*() or *apply() family of functions to apply them to a column of our tibble and data.table respectively.\n\n\nTidyverse\ndata.table\n\n\n\n\nmatch_stats_flat_tb |&gt; \n  mutate(\n    home_team_code = get_team_code(Home.team),\n    away_team_code = get_team_code(Away.team),\n    game_id = get_game_id(home_team_code, away_team_code, Date),\n    game_afltables_url = get_game_afltables_url(game_id, Season)\n  ) |&gt; \n  relocate(game_id, .before = Season) |&gt; \n  arrange(game_id) -&gt;\n  match_stats_flat_tb\n\n\n\n\nmatch_stats_flat_dt[, home_team_code := get_team_code(Home.team)]\nmatch_stats_flat_dt[, away_team_code := get_team_code(Away.team)]\nmatch_stats_flat_dt[, game_id := get_game_id(home_team_code, away_team_code, Date)]\nmatch_stats_flat_dt[, game_afltables_url := get_game_afltables_url(game_id, Season)]\n\nsetcolorder(match_stats_flat_dt, c(\"game_id\", setdiff(names(match_stats_flat_dt), \"game_id\")))\nsetkey(match_stats_flat_dt, game_id)\n\n# verify outputs match:\nidentical(as.data.frame(match_stats_flat_tb), as.data.frame(match_stats_flat_dt))\n\n[1] TRUE\n\n\n\n\n\nPlayer URLs\nIn a similar way we can add a player URL to our player_stats_* datasets, we start by creating a mapping table.\n\n\nTidyverse\ndata.table\n\n\n\n\n# non-duplicate URL: https://afltables.com/afl/stats/players/E/Errol_Gulden.html\n# duplicate URL: https://afltables.com/afl/stats/players/J/Josh_Kennedy0.html, https://afltables.com/afl/stats/players/J/Josh_Kennedy1.html\n# for dealing with duplicates, for example Peter Brown (6 of the same name!) seems to have a nonsensical order\nplayer_stats_tb |&gt; \n  mutate(full_name = paste(First.name, Surname, sep = \"_\")) |&gt; \n  distinct(ID, full_name) |&gt; \n  group_by(full_name) |&gt; \n  arrange(ID) |&gt;\n  mutate(\n    instance_number = as.character(cumsum(rep(1L, n())) - 1L),\n    dup_count = n()\n  ) |&gt; \n  mutate(\n    number_suffix = if_else(dup_count == 1L, \"\", instance_number),\n    first_letter = str_sub(full_name, 1, 1),\n    player_afltables_url = paste0(\"https://afltables.com/afl/stats/players/\", \n                                  first_letter, \"/\", full_name, number_suffix, \".html\")\n  ) |&gt; \n  ungroup() |&gt; \n  select(ID, player_afltables_url) -&gt;\n  player_url_tb\n\n# player_url_map_tb &lt;- `names&lt;-`(player_url_tb$player_url, player_url_tb$ID)\n\n\n\n\nplayer_url_dt &lt;- copy(player_stats_dt)\n\nplayer_url_dt[, full_name := paste(First.name, Surname, sep = \"_\")]\nplayer_url_dt &lt;- unique(player_url_dt, by = c(\"ID\", \"full_name\"))\nsetorder(player_url_dt, ID)\nplayer_url_dt &lt;- player_url_dt[, `:=`(\n  instance_number = as.character(cumsum(rep(1L, .N)) - 1L),\n  dup_count = .N\n), \"full_name\"]\n\nplayer_url_dt[, number_suffix := fifelse((dup_count == 1L), \"\", instance_number)]\nplayer_url_dt[, first_letter := str_sub(full_name, 1, 1)]\nplayer_url_dt[, player_afltables_url := paste0(\"https://afltables.com/afl/stats/players/\", \n                                     first_letter, \"/\", full_name, number_suffix, \".html\")]\nplayer_url_dt &lt;- player_url_dt[, .(ID, player_afltables_url)]\n# player_url_map_dt &lt;- `names&lt;-`(player_url_dt$player_url, player_url_dt$ID)\n\n# verify outputs match:\nidentical(as.data.frame(player_url_tb), as.data.frame(player_url_dt))\n\n[1] TRUE\n\n# identical(player_url_map_tb, player_url_map_dt)\n\n\n\n\nNow we can add add the game ID, game URL and player URL to the player_stats_* dataset.\n\n\nTidyverse\ndata.table\n\n\n\n\nplayer_stats_tb |&gt; \n  mutate(\n    home_team_code = get_team_code(Home.team),\n    away_team_code = get_team_code(Away.team),\n    game_id = get_game_id(home_team_code, away_team_code, Date),\n  ) |&gt; \n  left_join(match_stats_flat_tb |&gt; select(game_id, game_afltables_url), by = \"game_id\") |&gt; \n  left_join(player_url_tb, by = \"ID\") |&gt; \n  relocate(game_id, ID, .before = Season) |&gt;\n  arrange(game_id, Playing.for, ID) -&gt;\n  player_stats_tb\n\n\n\n\nplayer_stats_dt[, home_team_code := get_team_code(Home.team)]\nplayer_stats_dt[, away_team_code := get_team_code(Away.team)]\nplayer_stats_dt[, game_id := get_game_id(home_team_code, away_team_code, Date)]\n\nplayer_stats_dt &lt;- merge(\n  player_stats_dt, match_stats_flat_dt[, c(\"game_id\", \"game_afltables_url\")], \n  by = \"game_id\")\nplayer_stats_dt &lt;- merge(player_stats_dt, player_url_dt, by = \"ID\")\n\n\nsetcolorder(player_stats_dt, c(c(\"game_id\", \"ID\"), setdiff(names(player_stats_dt), c(\"game_id\", \"ID\"))))\nsetkey(player_stats_dt, game_id, Playing.for, ID)\n\n# verify outputs match:\nidentical(as.data.frame(player_stats_tb), as.data.frame(player_stats_dt))\n\n[1] TRUE"
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#finding-the-infamous-game",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#finding-the-infamous-game",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Finding the Infamous Game",
    "text": "Finding the Infamous Game\nLet’s use this new datasets to perform the simple exercise of obtaining the match ID for the aforementioned Swans versus Eagles game.\n\n\nTidyverse\ndata.table\n\n\n\n\n(\n  results_tb |&gt; \n    filter(Season == 2023, Round == \"R15\", Home.Team == \"Sydney\", \n           Away.Team == \"West Coast\") |&gt; \n    pull(Game) -&gt;\n    infamous_game_id_tb\n)\n\n[1] 16313\n\n\n\n\n\n(\n  infamous_game_id_dt &lt;- results_dt[\n    Season == 2023 & Round == \"R15\" & Home.Team == \"Sydney\" & \n      Away.Team == \"West Coast\", \n    Game\n    ]\n)\n\n[1] 16313\n\n# confirming:\nidentical(infamous_game_id_tb, infamous_game_id_dt)\n\n[1] TRUE\n\n\n\n\n\nWe can henceforth use this game ID whenever relevant to rank the swans."
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#highest-scoring-quarter",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#highest-scoring-quarter",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Highest Scoring Quarter",
    "text": "Highest Scoring Quarter\n\n\nTidyverse\ndata.table\n\n\n\nBreak down by\n\nEach quarter\n\n\nlibrary(dplyr)\nlibrary(stringr)\n\nplayer_stats_tb |&gt; \n  group_by(\n    Season, Round, Date, Local.start.time, Venue, Attendance, Home.team, \n    Away.team, Home.score, .data[[\"Away.score\"]]\n  ) |&gt; \n  summarise(count = n())\nresults_tb &lt;- as_tibble(results)\n\n\nplayer_stats_tb &lt;- as_tibble(player_stats)\nresults_tb &lt;- as_tibble(results)\n\n# verify that it has the same number of rows as the results data.\n\n\n\n\nlibrary(data.table)\nplayer_stats_dt &lt;- as.data.table(player_stats)\nresults_dt &lt;- as.data.table(results)\n\n\n\n\nComparing to the Swans Eagles Game\nWhile the swans scored heavily in the aforementioned game, it was not loaded so heavily in any particular so they are not really close to the highest scoring quarters. However, their third quarter score of 11 goals 5, 71 made it into the top ten of their highest scoring quarters. I actually didn’t need to run any R code to find this out as there is a page on AFL tables that summarises quarter score records here{targer = “_blank”}."
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-goal-kickers",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-goal-kickers",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Most Goal-kickers",
    "text": "Most Goal-kickers\nURL structure: https://afltables.com/afl/stats/games/YYYY/AABBYYYYMMDD.html\nwhere AA and BB are the team codes for two teams (described below) playing in ascending order (not order of home and away)\ne.g. https://afltables.com/afl/stats/games/1991/020419910803.html\nIndividual\nMultiple\nFive or More (Bags)"
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-one-sided-games",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-one-sided-games",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Most One-sided Games",
    "text": "Most One-sided Games"
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-clangers",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#most-clangers",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Most Clangers",
    "text": "Most Clangers\nDefine clanger"
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#worst-disposal-efficiency",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#worst-disposal-efficiency",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Worst Disposal Efficiency",
    "text": "Worst Disposal Efficiency\nDefine disposal efficiency"
  },
  {
    "objectID": "blog/2023/July/over-analysing-idle-footy-chat/index.html#youngest-norm-smith-medalist",
    "href": "blog/2023/July/over-analysing-idle-footy-chat/index.html#youngest-norm-smith-medalist",
    "title": "(Over-)Analysing Idle Footy Chat",
    "section": "Youngest Norm Smith Medalist",
    "text": "Youngest Norm Smith Medalist\nMake the below a collapsible callout (some of it doesn’t need to be)\nThis illustrates the fact that sometimes you need to stray outside of fitzRoy but it give most of the data you could ever want.\nBackground\nThe norm smith medal is award to the player adjudged best a field (best on ground) in the Grand Final.\nThe Norm Smith was first instituted in 1979 and prior to this, there was no official award given. However there is a source someone has provided of who they (and the media of the day) adjudged as being.\nWhile as a Western Australian, I would have no qualms with discarding the older, exclusively Victorian seasons, if not for the fact more data available is always nice (even if it is of more dubious quality).\nUnofficial source of older data https://themongrelpunt.com/footy-history/2020/04/30/before-the-norm-smith-best-on-ground-prior-to-1979/#:~:text=Robert%20Dipierdomenico%20was%20arguably%20best,the%2077%20Grand%20Final%20Replay.\nFor official norm smith which ever of the following are easier:\n\nhttps://www.afl.com.au/stats/leaders-awards/norm-smith-medal\nhttps://en.wikipedia.org/wiki/Norm_Smith_Medal#Recipients\n\nMake sure it lines up with the AFL data.\nFind the youngest player, player with least games"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Sport\n\n\nAFL\n\n\nR\n\n\nData\n\n\n\n\nThis blog post discusses the types of questions one often posits while watching the footy (or indeed any sport). I will use this article as a medium through which I can introduce analysis of AFL data in R.\n\n\n\n\n\n\n29 July 2023\n\n\nTim Gummer\n\n\n23 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "",
    "text": "Sport\n\n\nAFL\n\n\nR\n\n\nData\n\n\n\n\nThis blog post discusses the types of questions one often posits while watching the footy (or indeed any sport). I will use this article as a medium through which I can introduce analysis of AFL data in R.\n\n\n\n\n\n\n29 July 2023\n\n\nTim Gummer\n\n\n23 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "cv/index.html#download",
    "href": "cv/index.html#download",
    "title": "Curriculum Vitae",
    "section": "Download",
    "text": "Download\n\n\n\n\n  \n     Download current CV"
  },
  {
    "objectID": "cv/index.html#colophon",
    "href": "cv/index.html#colophon",
    "title": "Curriculum Vitae",
    "section": "Colophon",
    "text": "Colophon\n\nHow the CV(ausage) is made.\n\nMy resume was built in a “data-driven” fashion using the vitae R package and Excel1. It uses the beautiful Awesome CV template which I previously used in pure \\(\\LaTeX\\).1 Note that the linked YouTube video does not use Excel but I do.\nSharing\nIt is currently in a private repository on GitHub as it has some private information in it. There is also a visually consistent template for writing (cover) letters as well. I am happy to share the code with anyone who is interested. It probably is best suited to those familiar with \\(\\LaTeX\\), R and Excel2.2 I am not sure how large the intersection between these skill sets is but I personally find the workflow and resulting look very satisfying.\nIn the future I may make a clean template in a public repository to share with an accompanying blog post on how to use the template."
  },
  {
    "objectID": "cv/index.html#bit-of-fun",
    "href": "cv/index.html#bit-of-fun",
    "title": "Curriculum Vitae",
    "section": "Bit of Fun",
    "text": "Bit of Fun\nUnfortunately I do not have a video CV."
  },
  {
    "objectID": "goals/index.html#table-legend",
    "href": "goals/index.html#table-legend",
    "title": "Goals",
    "section": "Table Legend",
    "text": "Table Legend\nBelow is a legend for the Status and Completion fields."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tim Gummer",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n  \n  \n\nYou have reached the personal website of Tim Gummer. I am an Associate of Institute of Actuaries of Australia (AIAA). I am currently taking an 18 month leave of absence from my job as an Actuarial Analyst at Finity Consulting in order to spend more time on my actuarial studies (to become a fellow), with my family and on personal projects.\nI have built this website as a fun project. I would like to use it to chronicle some of my side projects. I enjoy these projects for their own sake and the main benefit I get out of them is learning and the satisfaction of building something cool. I hope that this website will provide me with further motivation to work on these projects (as well as being an enjoyable project in and of itself).\n\nThe content of this site will mix and match combinations of some of my particular interests/skills listed below:\n\nTools/Languages: R, VBA, Excel, \\(\\LaTeX\\), Python\nMethods: Statistics, Data Science (Collection, Visualisation, Modelling), Mathematics\nApplications: Sport (Australian Rules Football, Cricket)"
  },
  {
    "objectID": "index.html#welcome-to-my-website",
    "href": "index.html#welcome-to-my-website",
    "title": "Tim Gummer",
    "section": "",
    "text": "You have reached the personal website of Tim Gummer. I am an Associate of Institute of Actuaries of Australia (AIAA). I am currently taking an 18 month leave of absence from my job as an Actuarial Analyst at Finity Consulting in order to spend more time on my actuarial studies (to become a fellow), with my family and on personal projects.\nI have built this website as a fun project. I would like to use it to chronicle some of my side projects. I enjoy these projects for their own sake and the main benefit I get out of them is learning and the satisfaction of building something cool. I hope that this website will provide me with further motivation to work on these projects (as well as being an enjoyable project in and of itself).\n\nThe content of this site will mix and match combinations of some of my particular interests/skills listed below:\n\nTools/Languages: R, VBA, Excel, \\(\\LaTeX\\), Python\nMethods: Statistics, Data Science (Collection, Visualisation, Modelling), Mathematics\nApplications: Sport (Australian Rules Football, Cricket)"
  },
  {
    "objectID": "index.html#session-info",
    "href": "index.html#session-info",
    "title": "Tim Gummer",
    "section": "Session info",
    "text": "Session info\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22621)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   \n[3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      \n[5] LC_TIME=English_Australia.utf8    \n\ntime zone: Australia/Sydney\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.5   rstudioapi_0.14   yaml_2.3.7       \n [9] rmarkdown_2.22    knitr_1.43        jsonlite_1.8.5    xfun_0.39        \n[13] digest_0.6.31     rlang_1.1.1       evaluate_0.21    \n\nSys.time()\n\n[1] \"2023-07-25 15:41:36 AEST\""
  }
]